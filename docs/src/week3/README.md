# Week 3

## Class Notebooks:

Here are links to our current Notebooks: 

* [Latest StyleGAN2 General Training Notebook (512px)](https://colab.research.google.com/github/derekphilipau/machinelearningforartists/blob/main/stylegan2_ada_pytorch_all_new5.ipynb)
* [StyleGAN2 Transfer Learning with Faces Notebook (512px)](https://colab.research.google.com/github/derekphilipau/machinelearningforartists/blob/main/stylegan2_ada_pytorch_resume.ipynb)
* [StyleGAN2 Transfer Learning with Vases Notebook (1024px)](https://colab.research.google.com/github/derekphilipau/machinelearningforartists/blob/main/stylegan2_ada_pytorch_resume_vases.ipynb)


## Various StyleGAN2 links

### StyleGAN2-ADA ‚Äî Official PyTorch implementation

https://github.com/NVlabs/stylegan2-ada-pytorch

### dvschultz/stylegan2-ada-pytorch

new generators for stylegan2-ada-pytorch

https://github.com/dvschultz/stylegan2-ada-pytorch/blob/main/generate.py#L156

https://github.com/dvschultz/stylegan2-ada-pytorch

Colab
https://github.com/dvschultz/stylegan2-ada-pytorch/blob/main/SG2_ADA_PyTorch.ipynb

### StyleGAN2-Surgery

A collection of scripts and convenience modifications for creative media synthesis.

https://github.com/aydao/stylegan2-surgery

### pbaylies/projector_clip.py

https://gist.github.com/pbaylies/671ef8434fd11f056bab4330e0e7c365

### pbaylies/stylegan2-ada

https://github.com/pbaylies/stylegan2-ada
### Closed-Form Factorization of Latent Semantics in GANs

https://genforce.github.io/sefa/

### StyleGAN2-ada operations

https://colab.research.google.com/drive/1kW8H8IkaFhoIVhf1uUhVoc93zZqllmg2?authuser=1#scrollTo=xzA1-mt88AO_

### Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation

https://eladrich.github.io/pixel2style2pixel/

### StyleGAN2-ada for practice

This version of the newest PyTorch-based StyleGAN2-ada is intended mostly for fellow artists, who rarely look at scientific metrics, but rather need a working creative tool. Tested on Python 3.7 + PyTorch 1.7.1, requires FFMPEG for sequence-to-video conversions. For more explicit details refer to the original implementations.

https://github.com/eps696/stylegan2ada


### CLIP-GLaSS
https://colab.research.google.com/drive/1fWka_U56NhCegbbrQPt4PWpHPtNRdU49?usp=sharing#scrollTo=zvZFRZtcv8Mp

### Text-Guided Editing of Images (Using CLIP and StyleGAN)

https://github.com/orpatashnik/StyleCLIP

### Navigating StyleGAN2 w latent space using CLIP

https://github.com/l4rz/stylegan2-clip-approach

### Navigating StyleGAN2 ùëä latent space using CLIP
https://colab.research.google.com/drive/1IN3IgWQoB9WZGyz689COSGNnvnz7lIFI


### Aphantasia
https://github.com/eps696/aphantasia